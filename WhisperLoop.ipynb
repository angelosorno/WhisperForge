{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f595d4",
   "metadata": {},
   "source": [
    "Model Selector\n",
    "> turbo, base, small, medium, large, large-v2, large-v3-turbo, large-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"large-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417f82c",
   "metadata": {},
   "source": [
    "Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilita fallback CPU para ops no soportadas\n",
    "import os\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "import re, unicodedata, shutil, datetime, traceback, time\n",
    "import platform, torch, whisper\n",
    "import subprocess, json, hashlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbee8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"MPS built:\", getattr(torch.backends.mps, \"is_built\", lambda: None)())\n",
    "logger = globals().get(\"log_line\", print)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f30f4a",
   "metadata": {},
   "source": [
    "CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1257ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = \"cpu\"\n",
    "# FP16 = False  # en CPU no uses fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56aeeb",
   "metadata": {},
   "source": [
    "GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10697ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# FP16 = (DEVICE == \"cuda\")  # en GPU con CUDA sÃ­ conviene usar fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca69c529",
   "metadata": {},
   "source": [
    "Apple Silicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea3f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.backends.mps.is_available():\n",
    "#     DEVICE = \"mps\"\n",
    "#     FP16 = False\n",
    "# else:\n",
    "#     DEVICE = \"cpu\"\n",
    "#     FP16 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51b33c",
   "metadata": {},
   "source": [
    "Detectar Hardware: CUDA > MPS > CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOW_MPS = False\n",
    "\n",
    "def select_candidates():\n",
    "    cands = []\n",
    "    if torch.cuda.is_available():\n",
    "        cands.append((\"cuda\", True))      # CUDA con fp16\n",
    "    if ALLOW_MPS and getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "        cands.append((\"mps\", False))      # MPS con fp16=False\n",
    "    cands.append((\"cpu\", False))          # CPU\n",
    "    return cands\n",
    "\n",
    "def load_whisper_with_backoff(model_name: str):\n",
    "    logger = globals().get(\"log_line\", print)\n",
    "    last_err = None\n",
    "    for dev, fp16 in select_candidates():\n",
    "        try:\n",
    "            logger(f\"Cargando Whisper '{model_name}' en '{dev}' fp16={fp16}â€¦\")\n",
    "            model = whisper.load_model(model_name, device=dev)\n",
    "            # Contexto HW (opcional)\n",
    "            extra = \"\"\n",
    "            if dev == \"cuda\":\n",
    "                try:\n",
    "                    extra = f\" | GPU: {torch.cuda.get_device_name(0)} cap={torch.cuda.get_device_capability(0)}\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "            logger(f\"[HW] device={dev} fp16={fp16} torch={torch.__version__} os={platform.system()} {platform.release()}{extra}\")\n",
    "            return model, dev, fp16\n",
    "        except (NotImplementedError, RuntimeError) as e:\n",
    "            msg = str(e)\n",
    "            head = msg.splitlines()[0] if msg else e.__class__.__name__\n",
    "            # Fallos tÃ­picos de MPS (operador no soportado)\n",
    "            if (\"MPS\" in msg) or (\"SparseMPS\" in msg) or (\"aten::_sparse_coo_tensor_with_dims_and_tensors\" in msg):\n",
    "                logger(f\"[WARN] Backend {dev} fallÃ³: {head}. Probando siguiente opciÃ³nâ€¦\")\n",
    "                last_err = e\n",
    "                continue\n",
    "            # Fallos tÃ­picos de CUDA (drivers/lib no disponibles)\n",
    "            if (\"CUDA error\" in msg) or (\"no CUDA GPUs are available\" in msg) or (\"CUDA initialization\" in msg):\n",
    "                logger(f\"[WARN] Backend {dev} fallÃ³: {head}. Probando siguiente opciÃ³nâ€¦\")\n",
    "                last_err = e\n",
    "                continue\n",
    "            # Otros errores: propaga (para no ocultar problemas reales)\n",
    "            raise\n",
    "    raise last_err if last_err else RuntimeError(\"No fue posible cargar el modelo en ningÃºn backend\")\n",
    "\n",
    "# Uso\n",
    "model, DEVICE, FP16 = load_whisper_with_backoff(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8f36e",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31058e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORKDIR = Path.cwd()\n",
    "PENDING = WORKDIR / \"pending\"\n",
    "PROCESSING = WORKDIR / \"processing\"\n",
    "DONE = WORKDIR / \"done\"\n",
    "FAILED = WORKDIR / \"failed\"\n",
    "LOGFILE = WORKDIR / \"pipeline.log\"\n",
    "# NormalizaciÃ³n de audio (WAV 16 kHz mono PCM16)\n",
    "NORMALIZE_AUDIO = True  # False si quieres desactivarlo temporalmente\n",
    "AUDIO_EXTS = {\".wav\", \".m4a\", \".mp3\", \".flac\", \".ogg\", \".oga\", \".ogx\", \".opus\", \".aac\", \".wma\", \".caf\", \".aiff\", \".aif\", \".aifc\", \".amr\", \".alaw\", \".ulaw\", \".ac3\", \".eac3\", \".dts\", \".mp4\", \".m4v\", \".mov\", \".mkv\", \".mka\", \".webm\", \".weba\", \".avi\", \".3gp\", \".3g2\", \".flv\", \".ts\", \".mp2\", \".mp1\"}\n",
    "# \"long\" = YYYYMMDD-HHMMSS-name, \"short\" = MMDDHHMM-name\n",
    "NAME_STYLE = \"long\"\n",
    "LANG = \"es\"\n",
    "BEAM_SIZE = 8\n",
    "TEMPERATURE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL_PROMPT = (\n",
    "#     \"TranscripciÃ³n fiel en espaÃ±ol de un archivo de audio, cualquiera sea su contexto: conferencia, reuniÃ³n, clase, entrevista, discurso, enseÃ±anza, narraciÃ³n, conversaciÃ³n o grabaciÃ³n personal. \"\n",
    "#     \"Usar ortografÃ­a y gramÃ¡tica correctas, con buena puntuaciÃ³n, manteniendo la coherencia y fidelidad al contenido original. \"\n",
    "#     \"El estilo debe ser claro, estructurado y sin inventar informaciÃ³n. \"\n",
    "#     \"Palabras clave frecuentes: reuniÃ³n, conferencia, clase, enseÃ±anza, discurso, entrevista, conversaciÃ³n, narraciÃ³n, audio, transcripciÃ³n, documento, claridad, precisiÃ³n, fidelidad, coherencia, comprensiÃ³n, lenguaje, contexto.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b093d",
   "metadata": {},
   "source": [
    "Prompt IDMJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_PROMPT = (\n",
    "    \"TranscripciÃ³n fiel en espaÃ±ol\"\n",
    "    \"Usar ortografÃ­a y gramÃ¡tica correctas, con buena puntuaciÃ³n, manteniendo la coherencia y fidelidad al mensaje original. \"\n",
    "    \"Corresponde a una enseÃ±anza doctrinal de la Iglesia de Dios Ministerial de Jesucristo Internacional (IDMJI).\"\n",
    "    \"El estilo debe ser claro, estructurado y sin inventar informaciÃ³n. \"\n",
    "    # \"Cuando se mencione un versÃ­culo bÃ­blico, adicionalmente debe transcribirse con el siguiente formato entre corchetes, indicando libro, capÃ­tulo y versÃ­culos segÃºn la Biblia Reina-Valera 1960. Y se agrega justo despues de donde se menciona el versiculo. Ejemplo: [San Lucas 5:27-28]. \"\n",
    "    \"Palabras clave frecuentes: Iglesia, Doctrina, EnseÃ±anza, ProfecÃ­a, Biblia, Dios, EspÃ­ritu Santo.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc75afa",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d8ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nfc(s: str) -> str: return unicodedata.normalize(\"NFC\", s)\n",
    "def slugify(filename: str) -> str:\n",
    "    base = Path(filename).stem\n",
    "    base = unicodedata.normalize(\"NFC\", base).strip().casefold()\n",
    "    base = re.sub(r\"[.\\s]+\", \"-\", base)\n",
    "    base = re.sub(r\"[^\\w\\-.]+\", \"-\", base)\n",
    "    base = re.sub(r\"-{2,}\", \"-\", base).strip(\"-\")\n",
    "    return base or \"audio\"\n",
    "def ts_long() -> str: return datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "def ts_short() -> str: return datetime.datetime.now().strftime(\"%m%d%H%M\")\n",
    "def make_job_name(audio_path: Path) -> str:\n",
    "    ts = ts_long() if NAME_STYLE == \"long\" else ts_short()\n",
    "    model_tag = slugify(MODEL_NAME)\n",
    "    return f\"{ts}-{model_tag}-{slugify(audio_path.name)}\"\n",
    "def list_audios(pending_dir: Path):\n",
    "    def has_allowed_ext(p: Path) -> bool:\n",
    "        return any(ext.lower() in AUDIO_EXTS for ext in p.suffixes)\n",
    "    files = []\n",
    "    for p in pending_dir.iterdir():\n",
    "        if p.is_file():\n",
    "            if has_allowed_ext(p):\n",
    "                files.append(p)\n",
    "            else:\n",
    "                log_line(f\"[SKIP] {p.name} (ExtensiÃ³n no permitida)\")\n",
    "    return sorted(files, key=lambda p: p.stat().st_ctime)\n",
    "def log_line(msg: str):\n",
    "    LOGFILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with LOGFILE.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{datetime.datetime.now().isoformat()}  {msg}\\n\")\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a51455",
   "metadata": {},
   "source": [
    "RTF (Real-Time Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb68102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffprobe_duration(path: str | Path) -> float:\n",
    "    \"\"\"DuraciÃ³n en segundos usando ffprobe (preciso y rÃ¡pido).\"\"\"\n",
    "    out = subprocess.check_output([\n",
    "        \"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
    "        \"-of\", \"default=noprint_wrappers=1:nokey=1\", str(path)\n",
    "    ], text=True).strip()\n",
    "    try:\n",
    "        return float(out)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def sha1_file(path: Path) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(1<<20), b\"\"):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aff1bc",
   "metadata": {},
   "source": [
    "NormalizaciÃ³n de audio (WAV 16 kHz mono PCM16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09605bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wav_16k(in_path: Path, out_path: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Convierte cualquier entrada (audio o video) a WAV PCM 16 kHz mono.\n",
    "    -vn fuerza a ignorar video; aresample=soxr mejora la calidad del remuestreo.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", str(in_path),\n",
    "        \"-vn\",\n",
    "        \"-ac\", \"1\",\n",
    "        \"-af\", \"aresample=resampler=soxr:precision=33\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-c:a\", \"pcm_s16le\",\n",
    "        str(out_path)\n",
    "    ]\n",
    "    # Capturamos stdout/stderr para que el notebook no se llene de logs de ffmpeg\n",
    "    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    return out_path\n",
    "def prepareAudioforWhisper(src_path: Path, job_dir: Path, enabled: bool) -> Path:\n",
    "    \"\"\"\n",
    "    Si enabled=True â†’ genera job_dir/'input.16k.wav' y lo devuelve.\n",
    "    Si enabled=False â†’ devuelve el path original sin tocar.\n",
    "    \"\"\"\n",
    "    if not enabled:\n",
    "        return src_path\n",
    "    target = job_dir / \"input.16k.wav\"\n",
    "    return to_wav_16k(src_path, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537b9ab",
   "metadata": {},
   "source": [
    "Preparar carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e57c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in (PENDING, PROCESSING, DONE, FAILED): d.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea353c9",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ae358",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_line(f\"Cargando Whisper '{MODEL_NAME}' en '{DEVICE}' fp16={FP16}â€¦\")\n",
    "model = whisper.load_model(MODEL_NAME, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76a9af",
   "metadata": {},
   "source": [
    "Bucle Procesador de Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320891ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = list_audios(PENDING)\n",
    "if not audios:\n",
    "    print(\"No hay audios en ./pending.\")\n",
    "else:\n",
    "    total_jobs = 0\n",
    "    ok_jobs = 0\n",
    "    failed_jobs = 0\n",
    "    total_elapsed = datetime.timedelta()\n",
    "    total_audio_dur = 0.0\n",
    "    normalized_count = 0\n",
    "    rtfs = []\n",
    "\n",
    "    for audio_in in audios:\n",
    "        # --- crear carpeta de trabajo del job ---\n",
    "        job_name = make_job_name(audio_in)\n",
    "        job_dir = PROCESSING / job_name\n",
    "        job_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # --- copiar el original a processing/<job> ---\n",
    "        audio_tmp = job_dir / audio_in.name\n",
    "        shutil.copy2(str(audio_in), str(audio_tmp))\n",
    "\n",
    "        # --- cronÃ³metro: mide de principio a fin ---\n",
    "        start_wall = datetime.datetime.now()\n",
    "        start_perf = time.perf_counter()\n",
    "\n",
    "        # --- preparar fuente para Whisper (normalizar a 16k) con fallback ---\n",
    "        try:\n",
    "            src_for_whisper = prepareAudioforWhisper(audio_tmp, job_dir, enabled=NORMALIZE_AUDIO)\n",
    "            if src_for_whisper != audio_tmp:\n",
    "                log_line(f\"[AUDIO] Normalizado a 16k WAV: {src_for_whisper.name}\")\n",
    "            else:\n",
    "                log_line(f\"[AUDIO] Sin normalizar (usando original): {audio_tmp.name}\")\n",
    "            # Conteo de normalizados\n",
    "            if src_for_whisper != audio_tmp:\n",
    "                normalized_count += 1\n",
    "        except Exception as prep_err:\n",
    "            src_for_whisper = audio_tmp\n",
    "            log_line(f\"[AUDIO] PreparaciÃ³n fallÃ³, uso original: {audio_tmp.name} :: {prep_err}\")\n",
    "        log_line(f\"[START] {audio_in.name} -> {job_dir.name} [model={MODEL_NAME}, device={DEVICE}, fp16={FP16}]\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            # --- transcribir usando la fuente elegida ---\n",
    "            result = model.transcribe(\n",
    "                str(src_for_whisper),\n",
    "                language=LANG,\n",
    "                task=\"transcribe\",\n",
    "                temperature=TEMPERATURE,\n",
    "                beam_size=BEAM_SIZE,\n",
    "                patience=1.0,\n",
    "                condition_on_previous_text=True,\n",
    "                initial_prompt=INITIAL_PROMPT if INITIAL_PROMPT.strip() else None,\n",
    "                fp16=FP16\n",
    "            )\n",
    "\n",
    "            # --- limpiar texto ---\n",
    "            text = nfc(result.get(\"text\", \"\")).strip()\n",
    "            text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "            text = re.sub(r\"\\s+\\n\", \"\\n\", text).strip() + \"\\n\"\n",
    "\n",
    "            # --- escribir salida de texto ---\n",
    "            out_txt = job_dir / f\"{job_name}.txt\"\n",
    "            out_txt.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "            # --- mÃ©tricas y meta ---\n",
    "            end_wall = datetime.datetime.now()\n",
    "            elapsed = datetime.timedelta(seconds=(time.perf_counter() - start_perf))\n",
    "\n",
    "            audio_used_path = Path(src_for_whisper)\n",
    "            audio_duration = ffprobe_duration(audio_used_path)\n",
    "            rtf = (elapsed.total_seconds() / audio_duration) if audio_duration > 0 else None\n",
    "\n",
    "            last_end = None\n",
    "            try:\n",
    "                segs = result.get(\"segments\")\n",
    "                if isinstance(segs, list) and segs:\n",
    "                    last_end = float(segs[-1].get(\"end\", 0.0))\n",
    "            except Exception:\n",
    "                last_end = None\n",
    "            coverage_ratio = (last_end / audio_duration) if (last_end and audio_duration) else None\n",
    "\n",
    "            meta = {\n",
    "                \"job_name\": job_name,\n",
    "                \"start_time\": start_wall.isoformat(),\n",
    "                \"end_time\": end_wall.isoformat(),\n",
    "                \"elapsed_sec\": round(elapsed.total_seconds(), 3),\n",
    "                \"audio_duration_sec\": round(audio_duration, 3),\n",
    "                \"rtf\": round(rtf, 3) if rtf is not None else None,\n",
    "                \"coverage_last_segment_end_sec\": round(last_end, 3) if last_end is not None else None,\n",
    "                \"coverage_ratio\": round(coverage_ratio, 4) if coverage_ratio is not None else None,\n",
    "\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"device\": DEVICE,\n",
    "                \"fp16\": FP16,\n",
    "                \"language\": LANG,\n",
    "                \"beam_size\": BEAM_SIZE,\n",
    "                \"temperature\": (list(TEMPERATURE) if isinstance(TEMPERATURE, tuple) else TEMPERATURE),\n",
    "                \"initial_prompt_len\": len(INITIAL_PROMPT.strip()),\n",
    "\n",
    "                \"normalized_16k\": bool(NORMALIZE_AUDIO and audio_used_path.name.endswith(\"input.16k.wav\")),\n",
    "                \"input_original_name\": audio_in.name,\n",
    "                \"input_original_sha1\": sha1_file(audio_in),\n",
    "                \"input_used_name\": audio_used_path.name,\n",
    "                \"input_used_sha1\": sha1_file(audio_used_path),\n",
    "                \"output_txt\": out_txt.name,\n",
    "\n",
    "                \"chars\": len(text),\n",
    "                \"words\": len(text.split()),\n",
    "                \"segments\": (len(result.get(\"segments\", [])) if isinstance(result.get(\"segments\"), list) else None),\n",
    "\n",
    "                \"whisper_version\": getattr(whisper, \"__version__\", \"git\"),\n",
    "                \"torch_version\": torch.__version__,\n",
    "                \"os\": f\"{platform.system()} {platform.release()}\",\n",
    "            }\n",
    "\n",
    "            # --- escritura atÃ³mica de meta.json ---\n",
    "            tmp_meta = job_dir / \"meta.json.tmp\"\n",
    "            tmp_meta.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "            tmp_meta.replace(job_dir / \"meta.json\")\n",
    "\n",
    "            # --- mover a done y limpiar pending ---\n",
    "            final_dir = DONE / job_name\n",
    "            shutil.move(str(job_dir), str(final_dir))\n",
    "            audio_in.unlink(missing_ok=False)\n",
    "\n",
    "            log_line(f\"[DONE]  {audio_in.name} -> {final_dir} (DuraciÃ³n: {elapsed}, RTF={meta['rtf']})\")\n",
    "\n",
    "            total_jobs += 1\n",
    "            ok_jobs += 1\n",
    "            total_elapsed += elapsed\n",
    "            # Solo acumula duraciÃ³n/RTF si la duraciÃ³n es vÃ¡lida (>0)\n",
    "            if audio_duration and audio_duration > 0:\n",
    "                total_audio_dur += audio_duration\n",
    "                if rtf is not None:\n",
    "                    rtfs.append(rtf)\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_jobs += 1\n",
    "            total_jobs += 1\n",
    "            tb = traceback.format_exc()\n",
    "            log_line(f\"[FAIL]  {audio_in.name} :: {e}\")\n",
    "            (job_dir / \"error.log\").write_text(tb, encoding=\"utf-8\")\n",
    "            failed_dir = (WORKDIR / \"failed\" / job_name)\n",
    "            failed_dir.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.move(str(job_dir), str(failed_dir))\n",
    "            continue\n",
    "\n",
    "    print(\"\\n===== ðŸ“Š Informe de EjecuciÃ³n =====\")\n",
    "    print(f\"Total procesados: {total_jobs}\")\n",
    "    print(f\"  âœ… Exitosos: {ok_jobs}\")\n",
    "    print(f\"  âŒ Fallidos: {failed_jobs}\")\n",
    "\n",
    "    if total_jobs > 0:\n",
    "        print(f\"Normalizados: {normalized_count}/{total_jobs} \"\n",
    "            f\"({(100.0*normalized_count/total_jobs):.1f}%)\")\n",
    "\n",
    "    if ok_jobs > 0:\n",
    "        # Promedios solo con Ã©xitos y con duraciones vÃ¡lidas\n",
    "        if total_audio_dur > 0:\n",
    "            avg_audio = total_audio_dur / ok_jobs\n",
    "            print(f\"DuraciÃ³n promedio de audio: {avg_audio:.1f} s\")\n",
    "        else:\n",
    "            print(\"DuraciÃ³n promedio de audio: N/A\")\n",
    "\n",
    "        avg_elapsed = total_elapsed / ok_jobs\n",
    "        print(f\"Tiempo promedio de ejecuciÃ³n: {avg_elapsed}\")\n",
    "\n",
    "        if rtfs:\n",
    "            avg_rtf = sum(rtfs) / len(rtfs)\n",
    "            print(f\"RTF Promedio: {avg_rtf:.3f}\")\n",
    "        else:\n",
    "            print(\"RTF Promedio: N/A\")\n",
    "    else:\n",
    "        print(\"No hubo jobs exitosos.\")\n",
    "\n",
    "    print(\"===================================\")\n",
    "    print(\"\\nâœ… Terminado. Revisa la carpeta ./done para los finalizados y la carpeta ./pending para los no procesados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
